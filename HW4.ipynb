{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRmE2WI1pqTpaVsCUTWcN1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonju977/CV_hufs_25-1/blob/main/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_TPCXJclfMz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "Eed3SrzKmWW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. 이미지 다섯장을 수집하여 이미지 예측 실험"
      ],
      "metadata": {
        "id": "MYXzv9T-3TR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "\n",
        "image_paths = [\n",
        "    \"/content/drive/MyDrive/HUFS/dataset_CV/cake.jpeg\",\n",
        "    \"/content/drive/MyDrive/HUFS/dataset_CV/car.jpeg\",\n",
        "    \"/content/drive/MyDrive/HUFS/dataset_CV/cup.jpeg\",\n",
        "    \"/content/drive/MyDrive/HUFS/dataset_CV/doll.jpeg\",\n",
        "    \"/content/drive/MyDrive/HUFS/dataset_CV/flower.jpeg\"\n",
        "]\n",
        "\n",
        "#이미지 전처리\n",
        "images = []\n",
        "processed_images = []\n",
        "\n",
        "for path in image_paths:\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    images.append(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    processed_images.append(img_array)\n",
        "\n",
        "#배치 생성 및 예측, 디코딩\n",
        "input_batch = np.vstack(processed_images)\n",
        "\n",
        "predictions = model.predict(input_batch)\n",
        "\n",
        "decoded_predictions = decode_predictions(predictions, top=3)\n",
        "\n",
        "#결과출력(Top3까지)\n",
        "for i, pred in enumerate(decoded_predictions):\n",
        "    print(f\"Image: {image_paths[i].split('/')[-1]}\")\n",
        "    for rank, (class_id, class_name, score) in enumerate(pred):\n",
        "        print(f\"  Top {rank+1}: {class_name} ({score*100:.2f}%)\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "EERPbs0CmcY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 및 예측 결과 시각화\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "for i in range(len(images)):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "    #Top-1 예측 결과\n",
        "    top_pred = decoded_predictions[i][0]\n",
        "    class_name = top_pred[1]\n",
        "    score = top_pred[2]\n",
        "\n",
        "    plt.title(f\"{class_name}\\n({score*100:.2f}%)\", fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JgJ4-0FN3qMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. RestNet50의 구조와 파라미터 수"
      ],
      "metadata": {
        "id": "mv91XTbK5Ghx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "#모델 불러오기\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "#모델 구조 요약 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6_KdwfxanYXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. RestNet50으로 cats_and_dogs 파일 학습 및 실험"
      ],
      "metadata": {
        "id": "YJiQruEn5Sqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "\n",
        "\n",
        "!unzip -q \"/content/drive/MyDrive/HUFS/dataset_CV/cats_and_dogs_small.zip\" -d /content/\n",
        "\n",
        "\n",
        "base_dir = '/content/cats_and_dogs_small'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "#ResNet50 conv_base\n",
        "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "#특성 추출\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 20\n",
        "\n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 5, 5, 2048))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
        "        i += 1\n",
        "        if i * batch_size >= sample_count:\n",
        "            break\n",
        "    return features, labels\n",
        "\n",
        "#데이터 처리 및 훈련\n",
        "train_features, train_labels = extract_features(train_dir, 2000)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
        "test_features, test_labels = extract_features(test_dir, 1000)\n",
        "\n",
        "train_features = np.reshape(train_features, (2000, 5 * 5 * 2048))\n",
        "validation_features = np.reshape(validation_features, (1000, 5 * 5 * 2048))\n",
        "test_features = np.reshape(test_features, (1000, 5 * 5 * 2048))\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=5 * 5 * 2048))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_features, train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=20,\n",
        "                    validation_data=(validation_features, validation_labels))"
      ],
      "metadata": {
        "id": "oI08vZ1Wn0C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 결과 시각화\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'r-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, 'r-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NLc6vpM6zuQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. VGG16과 ResNet50 비교 및 include_top 제거 효과\n",
        "\n",
        "###4-1.VGG16 vs ResNet50 구조 및 파라미터 비교 (`include_top=False`)\n",
        "\n",
        "| 항목                         | VGG16                          | ResNet50                       |\n",
        "|------------------------------|---------------------------------|--------------------------------|\n",
        "| 입력 이미지 크기              | (150, 150, 3)                  | (150, 150, 3)                  |\n",
        "| 출력 Feature Map             | (4, 4, 512)                    | (5, 5, 2048)                   |\n",
        "| Flatten 후 차원 수            | 8192 (= 4×4×512)               | 51200 (= 5×5×2048)             |\n",
        "| 최상위 FC 구성               | Dense(256) → Dropout → Dense(1)| Dense(256) → Dropout → Dense(1)|\n",
        "| FC 계층 학습 파라미터 수      | 약 2.1M                        | 약 13.1M                       |\n",
        "| 전체 파라미터 수             | 약 16M                         | 약 25.6M                       |\n",
        "| 학습 속도                    | 빠름                           | 느림                           |\n",
        "| 일반화 성능 (Validation acc) | 양호                           | 일반적으로 더 우수함           |\n",
        "\n",
        "---\n",
        "\n",
        "###4-2.include_top=False 설정의 의미와 결과\n",
        "\n",
        "- `include_top=True`는 ImageNet용 원래 FC 분류기(`Dense(1000)` 등)를 포함한 구조.\n",
        "- `include_top=False`는 **CNN feature 추출기만 불러오고 최상위 FC 계층은 제외**한 구조.\n",
        "\n",
        " **Why? → 전이학습을 유연하게 적용하기 위해**\n",
        "\n",
        "###최상위 레이어 제거 효과 (Why `include_top=False`를 쓰는가?)\n",
        "\n",
        "1.**전이학습(Transfer Learning)이 가능해짐**  \n",
        "   - CNN이 이미 학습한 시각적 특징은 고정하고, 새로운 데이터셋에 맞춘 FC 계층만 학습 가능.\n",
        "\n",
        "2.**적은 양의 데이터로도 성능 확보 가능**  \n",
        "   - 기존 모델이 풍부한 시각 표현을 제공하므로, 소량의 데이터로도 높은 성능 가능.\n",
        "\n",
        "3.**클래스 수 유연하게 조정 가능**  \n",
        "   - 예: `Dense(1)`로 바꾸면 binary classification, `Dense(10)`이면 multi-class 가능.\n",
        "\n",
        "4.**학습 속도 향상**  \n",
        "   - CNN은 freeze 상태이며 최상단 FC만 학습 → 빠르고 효율적인 훈련 가능\n",
        "\n",
        "---\n",
        "\n",
        "###결론\n",
        "\n",
        "> VGG16은 비교적 얕고 학습 속도가 빠르지만, ResNet50은 더 깊은 구조로 인해 더 풍부한 특성을 추출할 수 있어 일반적으로 더 나은 성능을 보이게 된다.  `include_top=False` 설정은 기존 분류기를 제거하고, 도메인에 맞는 출력 구조로 재설계할 수 있게 해주어 전이학습의 핵심적인 요소라고 볼수 있음."
      ],
      "metadata": {
        "id": "ij75ptC_0lYb"
      }
    }
  ]
}